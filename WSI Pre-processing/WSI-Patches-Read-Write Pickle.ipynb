{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Loaded\n"
     ]
    }
   ],
   "source": [
    "import gc as g\n",
    "\n",
    "# %reset\n",
    "from IPython import get_ipython\n",
    "get_ipython().magic('reset -sf') \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(action='ignore',category=DeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore',category=FutureWarning)\n",
    "\n",
    "import pickle, sys,os,cv2, numpy as np, pandas as pd, scipy, seaborn as sns, json\n",
    "from random import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().magic('matplotlib inline')\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "from collections import Counter\n",
    "from itertools import cycle\n",
    "from six.moves import cPickle as pickle\n",
    "from scipy import interp\n",
    "from skimage.feature import local_binary_pattern,hog\n",
    "from skimage import data, exposure\n",
    "\n",
    "print('Libraries Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path,img_heighta,img_widtha,step):\n",
    "    \n",
    "    Images = []\n",
    "    y_M=[]    \n",
    "    k=0\n",
    "    \n",
    "    print('\\nPre-processing Files')\n",
    "    folder = sorted(os.listdir(path))\n",
    "    print(folder)\n",
    "    c = 0\n",
    "    for file in folder: \n",
    "        u = 0\n",
    "        subpath = os.listdir(os.path.join(path,file))      \n",
    "        print('\\nMajor Type : ',file)\n",
    "        print('Total # of Patches:',len(subpath))\n",
    "        for file1 in sorted(subpath):         \n",
    "            subpath1 = os.path.join(path,file,subpath[c])\n",
    "            img=cv2.imread(os.path.join(subpath1))\n",
    "            if step==1:\n",
    "                Images.append(cv2.resize(img, (img_heighta,img_widtha)))\n",
    "            else:\n",
    "                Images.append(img)            \n",
    "                \n",
    "            y_M.append(k)\n",
    "            u+=1\n",
    "            c+=1\n",
    "            \n",
    "        k+=1            \n",
    "        c=0\n",
    "    k=0\n",
    "    \n",
    "    Images_ = np.asarray(Images) \n",
    "    Labels_ = np.asarray(y_M)    \n",
    "    del Images, y_M\n",
    "\n",
    "    return Images_,Labels_        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_p(data_file,q):\n",
    "    # Reading dictionary to load train and test data\n",
    "    print('\\nTring to load pickle from %s' % data_file)\n",
    "    with open(data_file, 'rb') as file:\n",
    "        datasets = pickle.load(file)\n",
    "        dataset = datasets['dataset']\n",
    "    print('\\nPickle Loaded Successfully!')\n",
    "\n",
    "    X_train = dataset['X_train']\n",
    "    Y_train = dataset['Y_train']\n",
    "    del dataset\n",
    "\n",
    "    if q==1:\n",
    "        print('\\nX_train shape:', X_train.shape)\n",
    "        print('Y_train shape:', Y_train.shape)\n",
    "    \n",
    "    return X_train,Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savepickle(x_train,y_train, data_file):\n",
    "    print('\\nTrying to save pickle to %s' % data_file)\n",
    "    \n",
    "    X_train = x_train\n",
    "    Y_train = y_train\n",
    "    del x_train,y_train\n",
    "    \n",
    "    # creating dictionary to store train and test data\n",
    "    datasets = {\n",
    "        'dataset' : {'X_train': X_train,'Y_train': Y_train}}\n",
    "\n",
    "    with open(data_file, 'wb') as file:\n",
    "        pickle.dump(datasets, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        del datasets # to free up memory.\n",
    "    print('\\nPickle Saved Successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select DataSet\n",
      "\n",
      " 1-ICIAR2018 \n",
      " 2-Dartmouth \n",
      "1\n",
      "\n",
      "Select Class Type\n",
      "\n",
      " 1-Multi \n",
      " 2-Binary \n",
      "1\n",
      "\n",
      "Select Save or Load\n",
      "\n",
      " 1-Save \n",
      " 2-Load \n",
      "1\n",
      "\n",
      "\n",
      "\n",
      " DataSet-ICIAR2018 \n",
      "\n",
      "\n",
      "Pre-processing Files\n",
      "['D1', 'D2', 'D3', 'D4']\n",
      "\n",
      "Major Type :  D1\n",
      "Total # of Patches: 3770\n",
      "\n",
      "Major Type :  D2\n",
      "Total # of Patches: 1655\n",
      "\n",
      "Major Type :  D3\n",
      "Total # of Patches: 25590\n",
      "\n",
      "Major Type :  D4\n",
      "Total # of Patches: 1200\n",
      "\n",
      "Save Complete\n"
     ]
    }
   ],
   "source": [
    "print('\\nSelect DataSet')\n",
    "option_D0a = int(input(\"\\n 1-ICIAR2018 \\n 2-Dartmouth \\n\"))\n",
    "while option_D0a  not in (1,2,3,4,5):\n",
    "    option_D0a = int(input(\"\\n 1-ICIAR2018 \\n 2-Dartmouth \\n\"))\n",
    "\n",
    "print('\\nSelect Class Type')\n",
    "option_D0_C_T = int(input(\"\\n 1-Multi \\n 2-Binary \\n\"))\n",
    "while option_D0_C_T  not in (1,2):\n",
    "    option_D0_C_T = int(input(\"\\n 1-Multi \\n 2-Binary \\n\"))\n",
    "    \n",
    "print('\\nSelect Save or Load')\n",
    "option_D0_S = int(input(\"\\n 1-Save \\n 2-Load \\n\"))\n",
    "while option_D0_S  not in (1,2):\n",
    "    option_D0_S = int(input(\"\\n 1-Save \\n 2-Load \\n\"))\n",
    "    \n",
    "img_height, img_width = 40,40\n",
    "\n",
    "if option_D0a==1:\n",
    "    print(\"\\n\\n\\n DataSet-ICIAR2018 \\n\")\n",
    "    path  = \"D://Taimoor_Datasets\\Paper 2\\WSI\\Processed_Class_Wise\\RESULTS_DIRECTORY_TRAIN_ICIAR/\"\n",
    "    if option_D0_C_T==1:\n",
    "        data_file = 'PICKLESNEW/DataSet_ICIAR_AE_Train.pickle'\n",
    "        option_D0=2\n",
    "        num_classes=4\n",
    "        loss_a = 'categorical_crossentropy'\n",
    "    elif option_D0_C_T==2:\n",
    "        data_file = 'PICKLESNEW/DataSet_ICIAR_AE_Train_B.pickle'\n",
    "        option_D0=2\n",
    "        num_classes=2\n",
    "        loss_a = 'binary_crossentropy'\n",
    "\n",
    "elif option_D0a==2:\n",
    "    print(\"\\n\\n\\n DataSet-Dartmouth \\n\")\n",
    "    path  = \"D://Taimoor_Datasets\\Paper 2\\WSI\\Processed_Class_Wise\\RESULTS_DIRECTORY_Dart_LUNG/\"\n",
    "    if option_D0_C_T==1:\n",
    "        data_file = 'PICKLESNEW/DataSet_DART_AE_Train.pickle'   \n",
    "        option_D0=2\n",
    "        num_classes=5\n",
    "        loss_a = 'categorical_crossentropy'\n",
    "\n",
    "if option_D0_S==1:\n",
    "    (X_train_, Y_train_) = load_data(path,img_height, img_width,step=0)\n",
    "#     savepickle(X_train_,Y_train_,data_file)\n",
    "    \n",
    "    print('\\nSave Complete')\n",
    "    \n",
    "elif option_D0_S==2:\n",
    "    X_train_,Y_train_ = load_p(data_file,1)    \n",
    "    unique, counts = np.unique(Y_train_, return_counts=True)\n",
    "    abc= dict(zip(unique, counts))\n",
    "    print(abc)\n",
    "    for i in range(len(abc)):\n",
    "        print('Class %d: %d' % (i, abc[i]))    \n",
    "\n",
    "    print('\\nLoad Complete')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select DataSet\n",
      "\n",
      " 1-ICIAR2018 \n",
      " 2-Dartmouth \n",
      "1\n",
      "\n",
      "Select Class Type\n",
      "\n",
      " 1-Multi \n",
      " 2-Binary \n",
      "1\n",
      "\n",
      "Select Save or Load\n",
      "\n",
      " 1-Save \n",
      " 2-Load \n",
      "2\n",
      "\n",
      "\n",
      "\n",
      " DataSet-ICIAR2018 \n",
      "\n",
      "\n",
      "Tring to load pickle from PICKLESNEW/DataSet_ICIAR_AE_Train.pickle\n",
      "\n",
      "Pickle Loaded Successfully!\n",
      "\n",
      "X_train shape: (32215, 40, 40, 3)\n",
      "Y_train shape: (32215,)\n",
      "{0: 3770, 1: 1655, 2: 25590, 3: 1200}\n",
      "Class 0: 3770\n",
      "Class 1: 1655\n",
      "Class 2: 25590\n",
      "Class 3: 1200\n",
      "\n",
      "Load Complete\n"
     ]
    }
   ],
   "source": [
    "print('\\nSelect DataSet')\n",
    "option_D0a = int(input(\"\\n 1-ICIAR2018 \\n 2-Dartmouth \\n\"))\n",
    "while option_D0a  not in (1,2,3,4,5):\n",
    "    option_D0a = int(input(\"\\n 1-ICIAR2018 \\n 2-Dartmouth \\n\"))\n",
    "\n",
    "print('\\nSelect Class Type')\n",
    "option_D0_C_T = int(input(\"\\n 1-Multi \\n 2-Binary \\n\"))\n",
    "while option_D0_C_T  not in (1,2):\n",
    "    option_D0_C_T = int(input(\"\\n 1-Multi \\n 2-Binary \\n\"))\n",
    "    \n",
    "print('\\nSelect Save or Load')\n",
    "option_D0_S = int(input(\"\\n 1-Save \\n 2-Load \\n\"))\n",
    "while option_D0_S  not in (1,2):\n",
    "    option_D0_S = int(input(\"\\n 1-Save \\n 2-Load \\n\"))\n",
    "    \n",
    "img_height, img_width = 40,40\n",
    "\n",
    "if option_D0a==1:\n",
    "    print(\"\\n\\n\\n DataSet-ICIAR2018 \\n\")\n",
    "    path  = \"D://Taimoor_Datasets\\Paper 2\\WSI\\Processed_Class_Wise\\RESULTS_DIRECTORY_TRAIN_ICIAR/\"\n",
    "    if option_D0_C_T==1:\n",
    "        data_file = 'PICKLESNEW/DataSet_ICIAR_AE_Train.pickle'\n",
    "        option_D0=2\n",
    "        num_classes=4\n",
    "        loss_a = 'categorical_crossentropy'\n",
    "    elif option_D0_C_T==2:\n",
    "        data_file = 'PICKLESNEW/DataSet_ICIAR_AE_Train_B.pickle'\n",
    "        option_D0=2\n",
    "        num_classes=2\n",
    "        loss_a = 'binary_crossentropy'\n",
    "\n",
    "elif option_D0a==2:\n",
    "    print(\"\\n\\n\\n DataSet-Dartmouth \\n\")\n",
    "    path  = \"D://Taimoor_Datasets\\Paper 2\\WSI\\Processed_Class_Wise\\RESULTS_DIRECTORY_Dart_LUNG/\"\n",
    "    if option_D0_C_T==1:\n",
    "        data_file = 'PICKLESNEW/DataSet_DART_AE_Train.pickle'   \n",
    "        option_D0=2\n",
    "        num_classes=5\n",
    "        loss_a = 'categorical_crossentropy'\n",
    "\n",
    "if option_D0_S==1:\n",
    "    (X_train_, Y_train_) = load_data(path,img_height, img_width,step=0)\n",
    "    savepickle(X_train_,Y_train_,data_file)\n",
    "    \n",
    "    print('\\nSave Complete')\n",
    "    \n",
    "elif option_D0_S==2:\n",
    "    X_train_,Y_train_ = load_p(data_file,1)    \n",
    "    unique, counts = np.unique(Y_train_, return_counts=True)\n",
    "    abc= dict(zip(unique, counts))\n",
    "    print(abc)\n",
    "    for i in range(len(abc)):\n",
    "        print('Class %d: %d' % (i, abc[i]))    \n",
    "\n",
    "    print('\\nLoad Complete')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select DataSet\n",
      "\n",
      " 1-ICIAR2018 \n",
      " 2-Dartmouth \n",
      "1\n",
      "\n",
      "Select Class Type\n",
      "\n",
      " 1-Multi \n",
      " 2-Binary \n",
      "2\n",
      "\n",
      "Select Save or Load\n",
      "\n",
      " 1-Save \n",
      " 2-Load \n",
      "2\n",
      "\n",
      "\n",
      "\n",
      " DataSet-ICIAR2018 \n",
      "\n",
      "\n",
      "Tring to load pickle from PICKLESNEW/DataSet_ICIAR_AE_Train_B.pickle\n",
      "\n",
      "Pickle Loaded Successfully!\n",
      "\n",
      "X_train shape: (32215, 224, 224, 3)\n",
      "Y_train shape: (32215,)\n",
      "{0: 4970, 1: 27245}\n",
      "Class 0: 4970\n",
      "Class 1: 27245\n",
      "\n",
      "Load Complete\n"
     ]
    }
   ],
   "source": [
    "print('\\nSelect DataSet')\n",
    "option_D0a = int(input(\"\\n 1-ICIAR2018 \\n 2-Dartmouth \\n\"))\n",
    "while option_D0a  not in (1,2,3,4,5):\n",
    "    option_D0a = int(input(\"\\n 1-ICIAR2018 \\n 2-Dartmouth \\n\"))\n",
    "\n",
    "print('\\nSelect Class Type')\n",
    "option_D0_C_T = int(input(\"\\n 1-Multi \\n 2-Binary \\n\"))\n",
    "while option_D0_C_T  not in (1,2):\n",
    "    option_D0_C_T = int(input(\"\\n 1-Multi \\n 2-Binary \\n\"))\n",
    "    \n",
    "print('\\nSelect Save or Load')\n",
    "option_D0_S = int(input(\"\\n 1-Save \\n 2-Load \\n\"))\n",
    "while option_D0_S  not in (1,2):\n",
    "    option_D0_S = int(input(\"\\n 1-Save \\n 2-Load \\n\"))\n",
    "    \n",
    "img_height, img_width = 40,40\n",
    "\n",
    "if option_D0a==1:\n",
    "    print(\"\\n\\n\\n DataSet-ICIAR2018 \\n\")\n",
    "    path  = \"D://Taimoor_Datasets\\Paper 2\\WSI\\Processed_Class_Wise\\RESULTS_DIRECTORY_TRAIN_ICIAR/\"\n",
    "    if option_D0_C_T==1:\n",
    "        data_file = 'PICKLESNEW/DataSet_ICIAR_AE_Train.pickle'\n",
    "        option_D0=2\n",
    "        num_classes=4\n",
    "        loss_a = 'categorical_crossentropy'\n",
    "    elif option_D0_C_T==2:\n",
    "        data_file = 'PICKLESNEW/DataSet_ICIAR_AE_Train_B.pickle'\n",
    "        option_D0=2\n",
    "        num_classes=2\n",
    "        loss_a = 'binary_crossentropy'\n",
    "\n",
    "elif option_D0a==2:\n",
    "    print(\"\\n\\n\\n DataSet-Dartmouth \\n\")\n",
    "    path  = \"D://Taimoor_Datasets\\Paper 2\\WSI\\Processed_Class_Wise\\RESULTS_DIRECTORY_Dart_LUNG/\"\n",
    "    if option_D0_C_T==1:\n",
    "        data_file = 'PICKLESNEW/DataSet_DART_AE_Train.pickle'   \n",
    "        option_D0=2\n",
    "        num_classes=5\n",
    "        loss_a = 'categorical_crossentropy'\n",
    "\n",
    "if option_D0_S==1:\n",
    "    (X_train_, Y_train_) = load_data(path,img_height, img_width,step=0)\n",
    "    savepickle(X_train_,Y_train_,data_file)\n",
    "    \n",
    "    print('\\nSave Complete')\n",
    "    \n",
    "elif option_D0_S==2:\n",
    "    X_train_,Y_train_ = load_p(data_file,1)    \n",
    "    unique, counts = np.unique(Y_train_, return_counts=True)\n",
    "    abc= dict(zip(unique, counts))\n",
    "    print(abc)\n",
    "    for i in range(len(abc)):\n",
    "        print('Class %d: %d' % (i, abc[i]))    \n",
    "\n",
    "    print('\\nLoad Complete')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select DataSet\n",
      "\n",
      " 1-ICIAR2018 \n",
      " 2-Dartmouth \n",
      "2\n",
      "\n",
      "Select Class Type\n",
      "\n",
      " 1-Multi \n",
      " 2-Binary \n",
      "1\n",
      "\n",
      "Select Save or Load\n",
      "\n",
      " 1-Save \n",
      " 2-Load \n",
      "2\n",
      "\n",
      "\n",
      "\n",
      " DataSet-Dartmouth \n",
      "\n",
      "\n",
      "Tring to load pickle from PICKLESNEW/DataSet_DART_AE_Train.pickle\n",
      "\n",
      "Pickle Loaded Successfully!\n",
      "\n",
      "X_train shape: (188470, 40, 40, 3)\n",
      "Y_train shape: (188470,)\n",
      "{0: 38611, 1: 39092, 2: 40349, 3: 32228, 4: 38190}\n",
      "Class 0: 38611\n",
      "Class 1: 39092\n",
      "Class 2: 40349\n",
      "Class 3: 32228\n",
      "Class 4: 38190\n",
      "\n",
      "Load Complete\n"
     ]
    }
   ],
   "source": [
    "print('\\nSelect DataSet')\n",
    "option_D0a = int(input(\"\\n 1-ICIAR2018 \\n 2-Dartmouth \\n\"))\n",
    "while option_D0a  not in (1,2,3,4,5):\n",
    "    option_D0a = int(input(\"\\n 1-ICIAR2018 \\n 2-Dartmouth \\n\"))\n",
    "\n",
    "print('\\nSelect Class Type')\n",
    "option_D0_C_T = int(input(\"\\n 1-Multi \\n 2-Binary \\n\"))\n",
    "while option_D0_C_T  not in (1,2):\n",
    "    option_D0_C_T = int(input(\"\\n 1-Multi \\n 2-Binary \\n\"))\n",
    "    \n",
    "print('\\nSelect Save or Load')\n",
    "option_D0_S = int(input(\"\\n 1-Save \\n 2-Load \\n\"))\n",
    "while option_D0_S  not in (1,2):\n",
    "    option_D0_S = int(input(\"\\n 1-Save \\n 2-Load \\n\"))\n",
    "    \n",
    "img_height, img_width = 40,40\n",
    "\n",
    "if option_D0a==1:\n",
    "    print(\"\\n\\n\\n DataSet-ICIAR2018 \\n\")\n",
    "    path  = \"D://Taimoor_Datasets\\Paper 2\\WSI\\Processed_Class_Wise\\RESULTS_DIRECTORY_TRAIN_ICIAR/\"\n",
    "    if option_D0_C_T==1:\n",
    "        data_file = 'PICKLESNEW/DataSet_ICIAR_AE_Train.pickle'\n",
    "        option_D0=2\n",
    "        num_classes=4\n",
    "        loss_a = 'categorical_crossentropy'\n",
    "    elif option_D0_C_T==2:\n",
    "        data_file = 'PICKLESNEW/DataSet_ICIAR_AE_Train_B.pickle'\n",
    "        option_D0=2\n",
    "        num_classes=2\n",
    "        loss_a = 'binary_crossentropy'\n",
    "\n",
    "elif option_D0a==2:\n",
    "    print(\"\\n\\n\\n DataSet-Dartmouth \\n\")\n",
    "    path  = \"D://Taimoor_Datasets\\Paper 2\\WSI\\Processed_Class_Wise\\RESULTS_DIRECTORY_Dart_LUNG/\"\n",
    "    if option_D0_C_T==1:\n",
    "        data_file = 'PICKLESNEW/DataSet_DART_AE_Train.pickle'   \n",
    "        option_D0=2\n",
    "        num_classes=5\n",
    "        loss_a = 'categorical_crossentropy'\n",
    "\n",
    "if option_D0_S==1:\n",
    "    (X_train_, Y_train_) = load_data(path,img_height, img_width,step=0)\n",
    "    savepickle(X_train_,Y_train_,data_file)\n",
    "    \n",
    "    print('\\nSave Complete')\n",
    "    \n",
    "elif option_D0_S==2:\n",
    "    X_train_,Y_train_ = load_p(data_file,1)    \n",
    "    unique, counts = np.unique(Y_train_, return_counts=True)\n",
    "    abc= dict(zip(unique, counts))\n",
    "    print(abc)\n",
    "    for i in range(len(abc)):\n",
    "        print('Class %d: %d' % (i, abc[i]))    \n",
    "\n",
    "    print('\\nLoad Complete')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
